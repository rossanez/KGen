We present This benchmark is intended to evaluate the performance of DAMLOIL repositories with respect to extensional queries over a large data.
This benchmark is intended to evaluate the performance of DAMLOIL repositories with respect to extensional queries over a large data set that commits to a single realistic ontology.
This benchmark is intended to evaluate the performance of DAMLOIL repositories with respect to extensional queries over a large data consists of several performance metrics.
This benchmark is intended to evaluate the performance of DAMLOIL repositories with respect to extensional queries over a large data consists of the ontology.
This benchmark is intended to evaluate the performance of DAMLOIL repositories with respect to extensional queries over a large data consists of customizable synthetic data.
This benchmark is intended to evaluate the performance of DAMLOIL repositories with respect to extensional queries over a large data consists of a set of test queries.
Main features of the benchmark include an approach for measuring the degree to which a repository returns complete query answers.
a repeatable data set that can be scaled to an arbitrary size.
Main features of the benchmark include a plausible ontology for the university domain.
Main features of the benchmark include a repeatable data set.
We also show a benchmark experiment for the evaluation of DLDB.
We also show a benchmark experiment for the evaluation of a DAMLOIL repository.
a DAMLOIL repository that extends a relational database management system with description logic inference capabilities.